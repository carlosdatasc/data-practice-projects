{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2942d039-d461-4541-b4f7-2db786ccc930",
   "metadata": {},
   "source": [
    "## Precisión del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0129b167-2a53-4aac-a223-4ab929166afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b4713-bfc7-4013-9575-d06653cd5ebf",
   "metadata": {},
   "source": [
    "## Ejercicio 1 — Accuracy no siempre significa “bueno”\n",
    "Considera que si score > 0.5, el modelo predice “fraude”.\n",
    "\n",
    "Calcula accuracy, precision y recall.\n",
    "\n",
    "Observa qué pasa con la accuracy cuando cambias el umbral a 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0877bfc-7ea1-4a66-a75a-747002dd8a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>fraude_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  fraude_real\n",
       "0   0.01            0\n",
       "1   0.02            0\n",
       "2   0.98            1\n",
       "3   0.05            0\n",
       "4   0.99            1\n",
       "5   0.04            0\n",
       "6   0.03            0\n",
       "7   0.97            1\n",
       "8   0.01            0\n",
       "9   0.02            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simularemos un dataset básico\n",
    "data = {\n",
    "    'score':[0.01, 0.02, 0.98, 0.05, 0.99, 0.04, 0.03, 0.97, 0.01, 0.02],\n",
    "    'fraude_real': [0, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c4f8f5-567f-4114-beb6-3aee5de38863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "\n",
      "Accuracy con umbral 0.9:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "df['pred'] =(df['score']>0.5).astype(int)\n",
    "print(\"Accuracy: \", accuracy_score(df['fraude_real'],df['pred']))\n",
    "print('Precision: ',precision_score(df['fraude_real'],df['pred']))\n",
    "print('Recall: ',recall_score(df['fraude_real'],df['pred']))\n",
    "\n",
    "#Cambiar umbrals\n",
    "df['pred_alt'] = (df['score']>0.9).astype(int)\n",
    "print('\\nAccuracy con umbral 0.9: ',accuracy_score(df['fraude_real'],df['pred_alt']))\n",
    "print('Precision: ',precision_score(df['fraude_real'],df['pred_alt']))\n",
    "print('Recall: ', recall_score(df['fraude_real'],df['pred_alt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b641852-baab-4b23-8455-a26dbf198f48",
   "metadata": {},
   "source": [
    "## Ejercicio 2 — Precision vs Recall: el dilema ético\n",
    "\n",
    "Predice “enfermo” si prob_diagnostico > 0.7.\n",
    "\n",
    "Calcula precision, recall y F1-score.\n",
    "\n",
    "Repite cambiando el umbral a 0.3.\n",
    "\n",
    "Compara y analiza qué métrica sube o baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7fdc64e-2ab4-4222-8bfb-545b1b7cd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    'prob_diag':[0.95, 0.89, 0.15, 0.78, 0.05, 0.92, 0.35, 0.60, 0.10, 0.99],\n",
    "    'enfermo_real':[1, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7571bae1-91c1-4c59-a8ee-1a85ba8653ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Umbral: 0.3\n",
      "Precision: 0.8571428571428571\n",
      "Recall:  1.0\n",
      "F1-score:  0.9230769230769231\n",
      "\n",
      "Umbral: 0.7\n",
      "Precision: 1.0\n",
      "Recall:  0.8333333333333334\n",
      "F1-score:  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "for umbral in [0.3,0.7]:\n",
    "    df2['pred'] = (df2['prob_diag']>umbral).astype(int)\n",
    "    print(f'\\nUmbral: {umbral}')\n",
    "    print('Precision:' ,precision_score(df2['enfermo_real'],df2['pred']))\n",
    "    print('Recall: ',recall_score(df2['enfermo_real'],df2['pred']))\n",
    "    print('F1-score: ',f1_score(df2['enfermo_real'],df2['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa13e9-154c-49e4-9fb1-0ffe71f1a41b",
   "metadata": {},
   "source": [
    "## ROC-AUC: entender el comportamiento global del modelo\n",
    "\n",
    "Calcula el AUC del modelo.\n",
    "\n",
    "Interpreta su valor (0.5 = azar, 1 = perfecto).\n",
    "\n",
    "Si quieres, cambia manualmente los valores de “probabilidad” y observa cómo el AUC reacciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3ebe07-a9e9-4248-8b01-a586ba54d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = {\n",
    "    'prob':[0.1, 0.4, 0.35, 0.8, 0.95, 0.2, 0.7, 0.05, 0.85, 0.3],\n",
    "    'real': [0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718ecd3f-9da9-4f0c-8f1e-13ea69d3a1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(df3['real'],df3['prob'])\n",
    "print(f'AUC: {auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
